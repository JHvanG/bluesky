The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
Python 3.9.6
/scratch/s3813053/.envs/bluesky/bin/python3
2023-04-17 14:30:06.229784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-04-17 14:30:09.241898: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-04-17 14:30:09.269653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-17 14:30:32.922161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using Python-based geo functions
Reading config from /home2/s3813053/bluesky/settings.cfg
Reading magnetic variation data
Loading global navigation database...
Reading cache: /home2/s3813053/bluesky/cache/navdata.p
Warning: RTree could not be loaded. areafilter get_intersecting and get_knearest won't work
Successfully loaded OpenAP performance model
Failed to load BADA performance model
Successfully loaded legacy performance model
Successfully loaded plugin AREA
Successfully loaded plugin DATAFEED
Loading global navigation database...
Reading cache: /home2/s3813053/bluesky/cache/navdata.p
Loading global navigation database...
Reading cache: /home2/s3813053/bluesky/cache/navdata.p
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 64)                768       
                                                                 
 dense_1 (Dense)             (None, 32)                2080      
                                                                 
 dense_2 (Dense)             (None, 3)                 99        
                                                                 
=================================================================
Total params: 2,947
Trainable params: 2,947
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_3 (Dense)             (None, 64)                768       
                                                                 
 dense_4 (Dense)             (None, 32)                2080      
                                                                 
 dense_5 (Dense)             (None, 3)                 99        
                                                                 
=================================================================
Total params: 2,947
Trainable params: 2,947
Non-trainable params: 0
_________________________________________________________________
slurmstepd: error: *** JOB 327760 ON node50 CANCELLED AT 2023-04-17T14:33:32 ***

###############################################################################
H치br칩k Cluster
Job 327760 for user 's3813053'
Finished at: Mon Apr 17 14:33:33 CEST 2023

Job details:
============

Job ID              : 327760
Name                : atm_dqn_rel.sh
User                : s3813053
Partition           : regularlong
Nodes               : node50
Number of Nodes     : 1
Cores               : 1
Number of Tasks     : 1
State               : CANCELLED by 33813053,CANCELLED
Submit              : 2023-04-17T14:29:22
Start               : 2023-04-17T14:29:23
End                 : 2023-04-17T14:33:33
Reserved walltime   : 4-00:00:00
Used walltime       :   00:04:10
Used CPU time       :   00:02:34 (efficiency: 61.68%)
% User (Computation): 96.53%
% System (I/O)      :  3.47%
Mem reserved        : 2G
Max Mem (Node/step) : 388.82M (node50, per node)
Full Max Mem usage  : 388.82M
Total Disk Read     : 4.80M
Total Disk Write    : 683.59K

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
